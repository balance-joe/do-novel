# do-novel
使用大模型下载小说网站


```shell

# 创建环境
conda create -n do_novel_env python=3.12 -y

# 激活环境
conda activate do_novel_env

# 使用清华源安装
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt

```



# LLM 生成Xpath规则抓取小说站点

## 相关知识介绍
### LLM 大模型
生成式大语言模型并非凭空诞生，而是建立在几十年计算机科学发展的坚实基础上。因此，学习并理解过往的经典算法，能为我们深入掌握LLM的相关技术提供至关重要的帮助。
- 传统机器学习是由决策树,Bayes,SVM,KNN等算法构成的
    
    - Bayes: 利用经验和新证据来算出事件发生的可能性;
    
    - SVM: 寻找两类事物之间最宽的边界线,确保划分的分类足够清楚;
    
    - 决策树: 通过一套"if...else..."的规则,通过一串问题来把东西分类
    
    - KNN: "近朱者赤近墨者黑",一个东西是什么,由他身边最近的K个邻居来决定

- 深度学习 深度学习是机器学习的一个分支，它通过构建更深层的神经网络模型，尝试模拟人脑的分层处理机制，从而具备从数据中自动“学习”和“提取”复杂特征的能力。
    
    - 神经网络: 由多层神经元构成，数据从输入层进入，经过一个或多个隐藏层处理，最终由输出层产生结果。其核心运算包含 “加权求和” 与 “激活函
    数” 两部分，通过反向传播算法不断调整层与层之间连接的 “权重” 来学习
    
    - 卷积神经网络(CNN): CNN的核心是 “卷积” 操作，通过 “局部连接” 和 “权值共享” 的卷积核在输入数据上滑动，
    
    - 循环神经网络(RNN ):RNN的核心设计是 “循环连接” ，使网络的隐藏层不仅能处理当前输入，还能接收上一个时刻的隐藏状态，使得信息能在序列中 “循环” 传递，从而具备记忆上下文的能力。但其存在梯度消失问题，难以学习长程依赖。
    
    - Transformer: 核心机制是 “自注意力” ，可以计算序列中每个元素与所有其他元素之间的关联 “注意力分数” ，从而动态地为每个词分配不同的注意力，实现 “全局感知” 。它完全摒弃了循环结构，支持并行计算，并彻底解决了RNN难以处理长程依赖的问题，是现代大语言模型的基石架构。

### Ai Agent    
AI Agent（智能体）是一个能够感知环境、自主决策、执行动作以实现复杂目标的系统。它以大语言模型（LLM）作为“大脑”，但其核心能力超越了文本生成。

我们可以这样理解它的工作流程，这是一个感知-规划-行动的循环：

- 规划：LLM“大脑”将用户的复杂指令（如“为我策划一个北京三日游”）拆解成一步步的可执行计划（查天气、找景点、订酒店、排路线）。

- 行动：LLM调用各种工具（相当于“手和脚”），如执行搜索、调用计算器、运行代码、查询数据库等，来执行规划好的步骤。

- 观察：检查工具执行的结果（如搜索到的景点信息、查询到的机票价格），并根据这些新信息决定下一步行动。

### Xpath

XPath是一门在XML和HTML文档中导航、查询信息的语言。它通过路径表达式，像使用文件地址一样，精准定位文档中的节点（元素、属性、文本）。它不仅是网络爬虫定位元素的“瞄准镜”，也广泛应用于XML数据处理、Web测试脚本编写等场景。


## 初次构想
- 长期以来我都习惯使用txt格式加阅读器看小说，但是近些年小说似乎都开始不支持下载了，手机端也都有广告，看起来非常不方便；
- 近期，我尝试运用大模型和精准的提示词，从不同页面抓取固定内容，取得了不错的效果。当然，这目前还只是通过简单的 API 调用来实现的。
- 由近期学习Python和对LLM技术的深入研究所驱动，我构想出一个项目：通过开发一个智能Agent，来解析并获取不同网站的小说页面Xpath，进而实现高效的下载功能。
- 尽管智能体框架如 LangChain 或 CrewAI 发展迅速，但它们大多侧重于高层应用的快速搭建或多智能体协作。对于我当前需要从网页中精确提取XPath和小说内容的核心任务，一个能严格控制大模型输出的框架更为关键。因此，我选择了相对小众但理念独特的 pydantic-ai。它利用 Pydantic 模型进行类型验证，能确保大模型返回完全结构化、无误的数据，这为整个项目的稳定性和可靠性奠定了坚实基础。

## 项目架构

### 模块概览
项目在整体上划分为两个核心模块：**智能体** 与 **XPath 抓取执行器**。

### 配置驱动：项目的基石
本项目采用 **配置驱动** 的设计理念，选择 **YAML** 作为配置文件的格式，以实现规则与代码的分离，保证项目的灵活性与可维护性。

配置文件主要涵盖以下部分：
-   **站点基本信息**：如基础URL、编码格式等。
-   **请求头相关设置**：用于模拟浏览器行为，应对反爬策略。
-   **XPath 规则**：
    -   小说元信息XPath（如书名、作者）
    -   章节目录页XPath
    -   章节内容页XPath
-   **内容过滤规则**：用于清洗和过滤正文中的广告等无关内容。

### 智能体的核心使命
正是基于上述确定的配置规则与模板，智能体的任务得以明确：**其核心职责就是为特定网站自动生成或优化这份配置文件**，从而驱动抓取执行器完成工作。








