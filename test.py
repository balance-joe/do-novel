import os
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from pydantic_ai import Agent
from models.data_models import ChapterListConfig
from service import novel_service
from service.agent.generator_chapter_agent import XPathGeneratorChapterAgent
from service.agent.generator_content_agent import XPathGeneratorContentAgent
from service.crawl_service import CrawlService



if __name__ == "__main__":
    
    load_dotenv()

 # æµ‹è¯• HTML å†…å®¹
    test_html = """
    <html>
        <body>
            <div class="container">
                <h1>æµ‹è¯•æ ‡é¢˜</h1>
                <ul>
                    <li>é¡¹ç›®1</li>
                    <li>é¡¹ç›®2</li>
                    <li>é¡¹ç›®3</li>
                </ul>
                <a href="https://example.com" class="link">ç¤ºä¾‹é“¾æ¥</a>
            </div>
        </body>
    </html>
    """
    novel_service = novel_service.NovelService()
    
    # æµ‹è¯• 1ï¼šæå– h1 æ ‡é¢˜æ–‡æœ¬
    xpath1 = "//h1/text()"
    print("h1æ ‡é¢˜ï¼š", novel_service.extract_by_xpath(xpath1, test_html))  # è¾“å‡ºï¼š['æµ‹è¯•æ ‡é¢˜']
    
    # æµ‹è¯• 2ï¼šæå–æ‰€æœ‰ li æ–‡æœ¬
    xpath2 = "//ul/li"
    print("liåˆ—è¡¨ï¼š", novel_service.extract_by_xpath(xpath2, test_html))  # è¾“å‡ºï¼š['é¡¹ç›®1', 'é¡¹ç›®2', 'é¡¹ç›®3']
    
    # æµ‹è¯• 3ï¼šæå– a æ ‡ç­¾çš„ href å±æ€§
    xpath3 = "//a/@href"
    print("é“¾æ¥åœ°å€ï¼š", novel_service.extract_by_xpath(xpath3, test_html))  # è¾“å‡ºï¼š['https://example.com']
    
    # æµ‹è¯• 4ï¼šæ— æ•ˆ XPathï¼ˆè¯­æ³•é”™è¯¯ï¼‰
    xpath4 = "//div[@class=container]"  # ç¼ºå°‘å¼•å·
    print("æ— æ•ˆXPathç»“æœï¼š", novel_service.extract_by_xpath(xpath4, test_html))  # è¾“å‡ºé”™è¯¯æç¤ºå’Œç©ºåˆ—è¡¨



    # # è¯»å–æœ¬åœ° HTML æ–‡ä»¶å†…å®¹
    # path = './doc/content.html'
    # with open(path, 'r', encoding='utf-8') as file:
    #     html_content = file.read()
    

    # print(f"âœ… æˆåŠŸè¯»å–HTMLæ–‡ä»¶ï¼Œé•¿åº¦: {len(html_content)} å­—ç¬¦")
    
    # # åˆ›å»º CrawlService å®ä¾‹å¹¶æ¸…ç†HTML
    # crawl_service = CrawlService()
    # clean_html = crawl_service.extract_clean_body(html_content)
    
    # model_name= os.getenv("MODEL_NAME")  # ç›´æ¥è·å–å­—ç¬¦ä¸²
    # model_key=os.getenv("MODEL_KEY")    # ç›´æ¥è·å–å­—ç¬¦ä¸²
    # print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
    # print(f"ä½¿ç”¨å¯†é’¥: {model_key}")
    # return
    # generator = XPathGeneratorContentAgent(model_name, model_key)
    # print(generator.generate_rules(html=clean_html))
    
    
    # template = main()
    
    # if template:
    #     print("\nğŸ‰ XPathæ¨¡æ¿ç”Ÿæˆå®Œæˆï¼")
    #     print("æ‚¨å¯ä»¥å¤åˆ¶ä¸Šé¢çš„æ¨¡æ¿ç”¨äºæ‚¨çš„çˆ¬è™«é…ç½®ã€‚")
    #     print(template)
    # else:
    #     print("\nğŸ’¥ XPathæ¨¡æ¿ç”Ÿæˆå¤±è´¥ã€‚")